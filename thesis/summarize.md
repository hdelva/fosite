The university of Ghent has developed the Dodona platform which students can use to submit solutions and receive immediate feedback. This feedback is in large part done through unit testing which lets the students know whether or not their solution is correct, but it doesn't really help them forward if it's not. To remedy this, there is a visual debugger available which students can use to step through their program. Unfortunately it is limited in what it can do, file IO functionality isn't available for example. More importantly, it can only let the user scroll through execution states. If an error occurred after a couple of thousand executed statements, this becomes a very tedious process.

There are ways to avoid the pain of debugging altogether. There are linter tools such as JSLint and Pylint which emit warnings on error prone patterns. The Dodona platform uses these tools as well, and relays the warnings to the students. 

The Pylint tool for Python has noticeably helped students avoid mistakes. Which in turn allowed them to focus more on the actual assignment and less on learning how to program. The goal of this dissertation is to build on top of that, giving the students even more and even better feedback. An extensive data-flow analysis can untangle even the worst spaghetti code, which makes it a prime starting point for further analysis and feedback. 

NASA's source code of the Apollo 11 Guidance Computer was recently digitized and put on Github. All of it was written in an Assembly language and the result worked just fine. The C programming language was developed for the Unix operating system so the latter could run on various CPU architectures @cdev. In essence it's a pretty thin abstraction over Assembly, in the sense that it doesn't take much pressure off of the programmers. Unix worked just fine, just like NASA's guidance controller. One could argue that programmers don't need tools to aid them -- they seem to know what they're doing. 

As the field of computing grew, and with it the projects, it started becoming apparent that programmers can't always rely on themselves. Even veteran developers occasionally discover a major vulnerability in their code -- like the Heartbleed vulnerability in OpenSSL. Everyone makes mistakes of course, but critical code should avoid them at all costs. A first line of defense against these costly mistakes is a proof of correctness. NASA's code was reliable because they had formal proofs that the most critical parts were correct [@nasa1; @nasa2; @nasa3]. Doing this is a massive amount of work, and a proof can still be wrong. More importantly, most verification frameworks are applied to designs and not implementations @visser.

Functional programming languages are closely related to provable correctness, while also automating some of checks. Notable examples of such languages are Haskell and ML. Both have a strong theoretical foundation and provide the programmer with a strong type system to make code easier to reason about. This stands in stark contrast with languages like C. While Haskell was made to facilitate writing correct code @haskell, C was made to be close to the metal and efficient @cdev. The C compiler doesn't help the programmer nearly as much as the Haskell compiler. Developing correct and functional programs is obviously paramount to any programmer, so C's priorities don't always align with the developer's. 

That's where static analyzers come into play. They analyze a program, either in its source code form or its compiled form, and try to find as many possible mistakes as possible. These mistakes are often very subtle and rare, but even a single one can ruin someone's week. Code sample \ref{smp:shortset} comes from Google's Error Prone Github page and is a great example of how subtle serious bugs can be. The code seems to be just fine at first glance, the analysis in sample \ref{smp:shortset_f} reveals a subtle flaw.

Subtracting an `int` from a `short` results in an `int`. In this case it won't cause an actual bug yet because both types use the same hashing function, but this isn't something a developer should rely on. The JVM originally didn't support generics, and their implementation is still a bit rough. The `remove` method of a `List` instance accepts any `Object` instance. This can result in calls that never actually remove anything. If that call happens to only occur in a corner case in the $1000^{\text{th}}$ iteration of a loop, this can lead to some very confusing bugs. 

Every practical programming language is Turing complete, so in theory they should all be equal. This is a misconception that's been called the Turing tar-pit @tarpit. Everything is possible in a Turing tar-pit, but nothing of interest is easy. Programming languages where things of interest are perceived to be easy can be considered powerful. These languages are often the ones with lenient compilers or runtime environments such as C, Python, Javascript, ... In other words, languages that don't get in the way of the programmer too often. These are also by far the most popular languages.

As illustrated in the previous section this may not always be a good idea as humans tend to glance over subtle details. This makes the need for additional tools very important for any project that aims to achieve high reliability. The alternative is long and painful debugging sessions. At some point these languages no longer make it easy to do things of interest in. 

The C programming language has been one of the most popular programming languages for a couple of decades now. Depending on who you ask, the best thing about C is either its efficiency or its simplicity. The latter is what gives developers the power they desire. This comes at a cost however; with great power comes great responsibility.

Let's focus on the other main attraction of C, the efficiency. This comes at a cost as well and it's a one many people forget about. C's _raison d'Ãªtre_ isn't making developers feel good about themselves, it's generating efficient code. It was created to be a thin abstraction over various assembly languages that were limiting software development at the time @cdev. This has left some holes in the C specification; not all CPU architectures handle a division by zero for example, so the C specification doesn't specify what to do in this case. 

There are a lot of things the specification doesn't specify a behavior for, which leads to undefined behavior. Some are well-known, such as using freed memory. Others catch people by surprise, dividing by zero in C for example is undefined behavior. The GNU libc website still claims that `1/0` yields `inf` @gnu, even though the C99 clearly contradicts them @C99. The C99 standard introduced the `INF` macro, but it doesn't specify which operations should result in one. Division by zero is still as undefined as it has always been. 

Entire papers have been written on the subject of undefined behavior [@lattner; @wang; @guide]. One striking thing is how recent a lot of these papers are. Even though the language is over 40 years old, this is still an active field of research. Compilers are getting more advanced and with it the optimizations they perform. 

Code sample \ref{smp:undef} was part of PostgreSQL @wang. The call to `ereport` on line 2 never returns, it does some logging before calling `exit`. In the mind of the developer this prevents the division by zero on line 7. Looking at the code on Github, the function this sample came from indicates that calling it will return a `Datum` struct. According to the language specification, this function _must_ return a value each time it's called. The body of the null check does not return anything, so the compiler concludes that the rest of the function will also be executed and division by `arg2` will always get occur. 

Division by zero is also undefined in C, so the compiler concludes that `arg2` won't ever be zero -- it wouldn't get used in a division otherwise. As a result, the null check gets flagged as dead code, and is removed entirely. 

Not a single other programming language comes close to having as many external tools as C (and by extension C++). Many developers heavily depend on these tools in their usual workflow. One of the most established ones are the ones in Valgrind.

Valgrind is a suite of dynamic analysis tools, the most famous of which is Memcheck. Memory related bugs are some of the hardest to track down because because they're ultimately undefined behavior. For example, using a memory location after freeing might not always crash the program. There's an informal term for bugs like these: _heisenbugs_. Something might go wrong but when you try to isolate the cause everything seems to be just fine. Especially since Address Space Layout Randomization (ASLR) tends to be disabled during debugging but not during normal execution. 

This is where Memcheck comes into play. It analyses the program during regular execution and keeps track of what happens to the memory. This way it can notice memory related bugs such as use-after-free and report them back to the developer. Unfortunately it's not a perfect solution. There can be false positives as well as false negatives, and it is quite incompatible with some libraries such as OpenMPI @mpi. 

A lot of companies rely on analysis tools to manage their large C projects, and when there's demand in a market, the supply will follow. There's an impressive amount of commercial analysis tools available. Coverity is one of the most established ones. 

Dawson Engler is one of Coverity's co-founders is one of the leading researchers in the field of static analysis. He also co-authored a great paper in which he describes how difficult static analysis is in the real world @coverity. One particularly interesting part of the paper explains that there's a fundamental misunderstanding of what programming languages and compilers are. A programming language can exist as an abstract idea or a piece of paper. While the language a program is written in is whatever the compiler accepts. In other words, compilation is not certification. A good first step for a static analysis tool is to make sure that the input adheres to the specification. They go on to pose the hypothetical question: "Guess how receptive they are to fixing code the âofficialâ compiler accepted but the tool rejected with a parse error?"

Even with a plethora of tools available, C remains an untamed beast. Some tools like Valgrind are great at what they do but are still limited. Other tools like Coverity seem to fight stubborn developers as often as they fight bugs. 

According to Guido Van Rossum, he made Python because he wanted to make a descendant of ABC that would appeal to Unix/C hackers @lutz. This is a bit worrying considering the previous section, as C is a remarkably hard language to analyze.
Javascript's situation isn't great either. There are no namespaces, no modularization system, no classes, no interfaces, no encapsulation, and so on. Eric Lippert, who was on the ECMA committee during the early days has a Stackoverflow post where he discusses why Javascript is so ill-fit for static analysis and programming in the large @lippert. Even though Stackoverflow is a dubious source for any academic work, the author's experience should make up for it. 

Both are popular languages, so one might expect there to be a good amount of analysis tools for these languages as well. There seem to be two classes of analysis tools available for these languages right now: linters and type checkers. The linters are very popular, but as a later section will discuss they focus on error prone patterns instead of errors, and they prioritize efficiency over in-depth analysis. The type checkers are less popular, mostly due to circumstances. 

A type analysis tool for Javascript was developed in 2009, in part because the authors felt a need for deeper analysis than what JSLint could offer @jsure. They utilize an abstract interpreter to perform a flow- and context-sensitive analysis. Typescript was released a few years later, which fills a similar function as JSure, but with the researching power of Microsoft behind it. 
Python has a similar tool called MyPy which takes a fundamentally different approach @mypy. Python 3.5 introduced type hints for analysis tools such as MyPy to use. Although promising, the tool is plagued with a few limitations. For starters, it only supports Python versions since 3.5 and the most commonly used Python version is still 2.x. On top of that, most existing Python 3 code does not even use type hints at this point, so stand nothing to gain from MyPy. 

What the two classes of analysis tools for dynamic languages have in common is that they're not as in-depth as the ones of static languages. Tools like Coverity for C and Error Prone or FindBugs for Java go as far as detecting racing conditions, while the tools for Javascript and Python are still experimenting with type analysis. This isn't because dynamic languages aren't important, it's used to power some of the biggest websites [@netflix; @facebook], it's just a hard thing to do. The following anecdotal examples illustrate why and are supposed to be relatable.
